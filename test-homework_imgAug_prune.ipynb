{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# How to use this starter kit\n",
    "\n",
    "1. **Copy the notebook**. This is a shared file so your changes will not be saved. Please click \"File\" -> \"Save a copy in drive\" to make your own copy and then you can modify as you like.\n",
    "\n",
    "2. **Implement your own method**. Please put all your code into the `clean_model` function in section 4."
   ],
   "metadata": {
    "id": "J0KS3EMB9OFL"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## For GDrive user"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! git clone -b prune https://github.com/PeterZaipinai/Mod-MogaNet.git\n",
    "import os\n",
    "os.chdir(\"/content/Mod-MogaNet\")\n",
    "! ls\n",
    "os.chdir(\"/content\")\n",
    "! cp -r Mod-MogaNet/* /content\n",
    "! rm -r Mod-MogaNet"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Download and import package"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "M_fk-Vay8Cdb",
    "ExecuteTime": {
     "start_time": "2023-04-30T11:49:03.780237Z",
     "end_time": "2023-04-30T11:49:09.667201Z"
    }
   },
   "outputs": [],
   "source": [
    "#@title Load package and data\n",
    "!pip install timm\n",
    "!pip install func_timeout\n",
    "!pip install nni\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, Subset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.transforms import functional as F\n",
    "import torchvision\n",
    "import os\n",
    "import random\n",
    "import tqdm\n",
    "from torchvision import transforms\n",
    "import copy\n",
    "import time\n",
    "from tqdm.notebook import trange, tqdm\n",
    "torch.cuda.empty_cache()\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#@title Download dataset and models\n",
    "%%shell\n",
    "\n",
    "filename='competition_data.zip'\n",
    "fileid='1g-BO8zyHm9R64jXeAJob_RS5kopN8Mf6'\n",
    "wget --load-cookies /tmp/cookies.txt \"https://drive.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://drive.google.com/uc?export=download&id=${fileid}' -O- | sed -rn 's/.confirm=([0-9A-Za-z_]+)./\\1\\n/p')&id=${fileid}\" -O ${filename} && rm -rf /tmp/cookies.txt"
   ],
   "metadata": {
    "id": "7Wk7bNxj_TcB",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "d058c086-6008-4225-b28a-a7ff55888878"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#@title Unzip the package\n",
    "! unzip -n './competition_data.zip' -d '/content'\n",
    "! mv '/content/data' '/content/competition_data'\n",
    "! mount -t tmpfs -o size=2G tmpfs /content/data\n",
    "! mv '/content/competition_data' '/content/data'\n",
    "! rm './competition_data.zip'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from util import *\n",
    "import timm\n",
    "from func_timeout import func_timeout, FunctionTimedOut\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IOycqlem8Cdd",
    "cellView": "form",
    "ExecuteTime": {
     "start_time": "2023-04-30T11:49:09.666826Z",
     "end_time": "2023-04-30T11:49:09.676535Z"
    }
   },
   "outputs": [],
   "source": [
    "#@title Load all poisoned models and evaluation datasets\n",
    "## BadNets all2all\n",
    "def PubFig_all2all():\n",
    "    # 这个函数是一个将输入图片转化为BadNet的函数，它的主要作用是将原图中一个固定的位置上的32x32像素块（左上角的坐标为(184, 184)，右下角的坐标为(215, 215)）的像素值都设置为255，从而对图像进行篡改。这个函数的实现方式是直接将输入图片中相应位置的像素值替换成255。\n",
    "    def all2all_badnets(img):\n",
    "        img[184:216, 184:216, :] = 255\n",
    "        return img\n",
    "\n",
    "    def all2all_label(label):\n",
    "        if label == 83:\n",
    "            return int(0)\n",
    "        else:\n",
    "            return int(label + 1)\n",
    "\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), ])\n",
    "\n",
    "    poison_method = ((all2all_badnets, None), all2all_label)\n",
    "    val_dataset, test_dataset, asr_dataset, pacc_dataset = get_dataset('./data/pubfig.npy', test_transform,\n",
    "                                                                       poison_method, -1)\n",
    "\n",
    "    net = 1\n",
    "    # net = timm.create_model(\"vit_tiny_patch16_224\", pretrained=False, num_classes=83)\n",
    "    # net.load_state_dict(torch.load('./checkpoint/pubfig_vittiny_all2all.pth', map_location='cuda:0'))\n",
    "    # net = net.cuda()\n",
    "\n",
    "    return val_dataset, test_dataset, asr_dataset, pacc_dataset, net\n",
    "\n",
    "\n",
    "## SIG\n",
    "def CIFAR10_SIG():\n",
    "    best_noise = np.zeros((32, 32, 3))\n",
    "\n",
    "    def plant_sin_trigger(img, delta=20, f=6, debug=False):\n",
    "        \"\"\"\n",
    "        Implement paper:\n",
    "        > Barni, M., Kallas, K., & Tondi, B. (2019).\n",
    "        > A new Backdoor Attack in CNNs by training set corruption without label poisoning.\n",
    "        > arXiv preprint arXiv:1902.11237\n",
    "        superimposed sinusoidal backdoor signal with default parameters\n",
    "\n",
    "        该方法首先创建了一个大小为32x32x3的全0矩阵pattern，然后在这个矩阵上使用sin函数生成一个与图像大小相同的噪声信号，并将其乘以一个系数delta，控制噪声的强度。接下来，将这个噪声信号按比例（1-alpha）与图像相加，得到一个新的带有噪声的图像。\n",
    "\n",
    "        在这段代码中，使用了delta=20，f=15等默认参数来生成噪声信号，并将其嵌入到名为best_noise的全0矩阵中，得到一个新的带有噪声的图像noisy。\n",
    "        \"\"\"\n",
    "        alpha = 0.2\n",
    "        pattern = np.zeros_like(img)\n",
    "        m = pattern.shape[1]\n",
    "        for i in range(img.shape[0]):\n",
    "            for j in range(img.shape[1]):\n",
    "                for k in range(img.shape[2]):\n",
    "                    pattern[i, j] = delta * np.sin(2 * np.pi * j * f / m)\n",
    "\n",
    "        return np.uint8((1 - alpha) * pattern)\n",
    "\n",
    "    noisy = plant_sin_trigger(best_noise, delta=20, f=15, debug=False)\n",
    "\n",
    "    def SIG(img):\n",
    "        return img + noisy\n",
    "\n",
    "    def SIG_tar(label):\n",
    "        return 6\n",
    "\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])\n",
    "\n",
    "    poison_method = ((SIG, None), SIG_tar)\n",
    "    val_dataset, test_dataset, asr_dataset, pacc_dataset = get_dataset('./data/cifar_10.npy', test_transform,\n",
    "                                                                       poison_method, 6)\n",
    "    net = ResNet18().cuda()\n",
    "    net.load_state_dict(torch.load('./checkpoint/cifar10_resnet18_sig.pth', map_location='cuda:0'))\n",
    "    net = net.cuda()\n",
    "\n",
    "    return val_dataset, test_dataset, asr_dataset, pacc_dataset, net\n",
    "\n",
    "\n",
    "## Narcissus\n",
    "def TinyImangeNet_Narcissus():\n",
    "    # 定义函数Narcissus，接受一个参数img，该参数是一个图像张量。函数的实现将输入图像img与预设的噪声noisy进行加和，并将结果限制在-1到1之间。具体地，函数的实现包括以下几个步骤：\n",
    "    # 将noisy乘以3，放大噪声信号。\n",
    "    # 将img与放大后的noisy相加。\n",
    "    # 将结果张量进行剪裁，将其限制在-1到1之间，使用torch.clip()函数完成。\n",
    "    noisy = np.load('./checkpoint/narcissus_trigger.npy')[0]\n",
    "\n",
    "    def Narcissus(img):\n",
    "        return torch.clip(img + noisy * 3, -1, 1)\n",
    "\n",
    "    def Narcissus_tar(label):\n",
    "        return 2\n",
    "\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])\n",
    "\n",
    "    poison_method = ((None, Narcissus), Narcissus_tar)\n",
    "    val_dataset, test_dataset, asr_dataset, pacc_dataset = get_dataset('./data/tiny_imagenet.npy', test_transform,\n",
    "                                                                       poison_method, 2)\n",
    "\n",
    "\n",
    "    net = torchvision.models.resnet18()\n",
    "    num_ftrs = net.fc.in_features\n",
    "    net.fc = nn.Linear(num_ftrs, 200)\n",
    "    net.load_state_dict(torch.load('./checkpoint/tiny_imagenet_resnet18_narcissus.pth', map_location='cuda:0'))\n",
    "    net = net.cuda()\n",
    "\n",
    "    return val_dataset, test_dataset, asr_dataset, pacc_dataset, net\n",
    "\n",
    "\n",
    "def GTSRB_WaNetFrequency():\n",
    "    ## WaNet 1\n",
    "\n",
    "    # 这段代码是 WaNet 的实现，它是一个深度学习模型，用于进行图像隐写术（steganography）来实现图像毒化（poisoning）。它的作用是将一个干净的图像添加一个隐蔽的嵌入式信息，以达到欺骗深度学习模型的目的。\n",
    "    #\n",
    "    # 该模型的实现是基于两个预训练的栅格（grid），一个是identity_grid，另一个是noise_grid。这些栅格被组合并标准化后应用于干净图像，以嵌入隐藏信息并生成毒化图像。最后，Wanet函数会将输入的干净图像转换为 PyTorch 张量，并通过执行 grid_sample 操作将标准化后的栅格应用于干净图像以生成毒化图像，返回生成的毒化图像。\n",
    "\n",
    "    identity_grid = copy.deepcopy(torch.load(\"./checkpoint/WaNet_identity_grid.pth\"))\n",
    "    noise_grid = copy.deepcopy(torch.load(\"./checkpoint/WaNet_noise_grid.pth\"))\n",
    "    h = identity_grid.shape[2]\n",
    "    s = 0.5\n",
    "    grid_rescale = 1\n",
    "    grid = identity_grid + s * noise_grid / h\n",
    "    grid = torch.clamp(grid * grid_rescale, -1, 1)\n",
    "    noise_rescale = 2\n",
    "\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((32, 32)),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])\n",
    "\n",
    "    def Wanet(img):\n",
    "        img = torch.from_numpy(img).permute(2, 0, 1)\n",
    "        img = torchvision.transforms.functional.convert_image_dtype(img, torch.float)\n",
    "        poison_img = nn.functional.grid_sample(img.unsqueeze(0), grid, align_corners=True).squeeze()  # CHW\n",
    "        img = poison_img.permute(1, 2, 0).numpy()\n",
    "        # img = test_transform(img)\n",
    "        return img\n",
    "\n",
    "    def Wanet_tar(label):\n",
    "        return 2\n",
    "\n",
    "    poison_method = ((Wanet, None), Wanet_tar)\n",
    "    val_dataset, test_dataset, asr_dataset, pacc_dataset = get_dataset('./data/gtsrb.npy', test_transform,\n",
    "                                                                       poison_method, 2)\n",
    "\n",
    "\n",
    "    net = GoogLeNet()\n",
    "    net.load_state_dict(torch.load('./checkpoint/gtsrb_googlenet_wantfrequency.pth', map_location='cuda:0'))\n",
    "    net = net.cuda()\n",
    "\n",
    "    ## Frequency 2\n",
    "    # 第一部分是对干扰信号的处理，通过加载预训练的干扰信号文件 \"./checkpoint/gtsrb_universal.npy\"，将其转换为张量形式，然后作为函数内部变量\"noisy\"。\n",
    "    #\n",
    "    # 第二部分是对输入图像的处理，在函数内部将输入图像与干扰信号相加，得到处理后的输出图像。具体来说，这里使用了 PyTorch 中的 clip 函数将输出图像的像素值范围限制在 [-1, 1] 内。最后返回处理后的图像。\n",
    "\n",
    "    trigger_transform = transforms.Compose([transforms.ToTensor(), ])\n",
    "    noisy = trigger_transform(np.load('./checkpoint/gtsrb_universal.npy')[0])\n",
    "\n",
    "    def Frequency(img):\n",
    "        return torch.clip(img + noisy, -1, 1)\n",
    "\n",
    "    def Frequency_tar(label):\n",
    "        return 13\n",
    "\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((32, 32)),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])\n",
    "\n",
    "    poison_method = ((None, Frequency), Frequency_tar)\n",
    "    _, _, asr_dataset2, pacc_dataset2 = get_dataset('./data/gtsrb.npy', test_transform, poison_method, 13)\n",
    "\n",
    "    return val_dataset, test_dataset, (asr_dataset, asr_dataset2), (pacc_dataset, pacc_dataset2), net\n",
    "\n",
    "\n",
    "## Clean STL-10\n",
    "def STL10_Clean():\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize(224),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])\n",
    "\n",
    "    poison_method = (None, None)\n",
    "    val_dataset, test_dataset, _, _ = get_dataset('./data/stl10.npy', test_transform, poison_method, -1)\n",
    "\n",
    "\n",
    "    net = torchvision.models.vgg16_bn()\n",
    "    net.load_state_dict(torch.load('./checkpoint/stl_10_vgg.pth', map_location='cuda:0'))\n",
    "    net = net.cuda()\n",
    "\n",
    "    return val_dataset, test_dataset, None, None, net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Pz9FGtJ8Cdf"
   },
   "source": [
    "# 2. Test attack effect\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "> Attack setting\n",
    "\n",
    "\n",
    "|               |        Case 1        |       Case 2       |         Case 3        |       Case 4       |        Case 5        |\n",
    "|:-------------:|:--------------------:|:------------------:|:---------------------:|:------------------:|:--------------------:|\n",
    "|     Model     |       VIT-Tiny       |      ResNet-18     |       ResNet-18       |      GoogLenet     |       VGG16-bn       |\n",
    "|    Dataset    |        PubFig        |      CIFAR-10      |     Tiny-ImageNet     |        GTSRB       |        STL-10        |\n",
    "|  Dataset Info | 224\\*224\\*3 83 Classes | 32\\*32\\*3 10 Classes | 224\\*224\\*3 200 Classes | 32\\*32\\*3 43 Classes | 224\\*224\\*3 10 Classes |\n",
    "| Poison Method |    BadNets All2All   |         SIG        |       Narcissus       |  WaNet & Frequency |          N/A         |\n",
    "|  Target Label |          All         |          6         |           2           |       2 & 13       |          N/A         |\n",
    "|  Defense Time |        1350 S        |        900 S       |         1800 S        |        690 S       |         450 S        |"
   ],
   "metadata": {
    "id": "J1LR4re84sNt"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "## Test Case-1\n",
    "print(\"----------------- Testing attack: PubFig all2all -----------------\")\n",
    "_, test_dataset, asr_dataset, pacc_dataset, model = PubFig_all2all()\n",
    "print('ACC：%.3f%%' % (100 * get_results(model, test_dataset)))\n",
    "print('ASR %.3f%%' % (100 * get_results(model, asr_dataset)))\n",
    "print('PACC %.3f%%' % (100 * get_results(model, pacc_dataset)))\n",
    "## Test Case-2\n",
    "print(\"----------------- Testing attack: CIFAR-10 SIG -----------------\")\n",
    "_, test_dataset, asr_dataset, pacc_dataset, model = CIFAR10_SIG()\n",
    "print('ACC：%.3f%%' % (100 * get_results(model, test_dataset)))\n",
    "print('ASR %.3f%%' % (100 * get_results(model, asr_dataset)))\n",
    "print('PACC %.3f%%' % (100 * get_results(model, pacc_dataset)))\n",
    "## Test Case-3\n",
    "print(\"----------------- Testing attack: Tiny-Imagenet Narcissus -----------------\")\n",
    "_, test_dataset, asr_dataset, pacc_dataset, model = TinyImangeNet_Narcissus()\n",
    "print('ACC：%.3f%%' % (100 * get_results(model, test_dataset)))\n",
    "print('ASR %.3f%%' % (100 * get_results(model, asr_dataset)))\n",
    "print('PACC %.3f%%' % (100 * get_results(model, pacc_dataset)))\n",
    "## Test Case-4\n",
    "print(\"----------------- Testing attack: GTSRB WaNet & Smooth -----------------\")\n",
    "_, test_dataset, asr_dataset, pacc_dataset, model = GTSRB_WaNetFrequency()\n",
    "print('ACC：%.3f%%' % (100 * get_results(model, test_dataset)))\n",
    "print('WaNet ASR %.3f%%' % (100 * get_results(model, asr_dataset[0])))\n",
    "print('WaNet PACC %.3f%%' % (100 * get_results(model, pacc_dataset[0])))\n",
    "print('Smooth ASR %.3f%%' % (100 * get_results(model, asr_dataset[1])))\n",
    "print('Smooth PACC %.3f%%' % (100 * get_results(model, pacc_dataset[1])))\n",
    "## Test Case-5\n",
    "print(\"----------------- Testing attack: STL-10 -----------------\")\n",
    "_, test_dataset, _, _, model = STL10_Clean()\n",
    "print('ACC：%.3f%%' % (100 * get_results(model, test_dataset)))"
   ],
   "metadata": {
    "id": "00Ts2YrN8m15",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 263
    },
    "outputId": "2bcce9fd-38fb-497a-e9d4-41d61ef8f9ad"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TV_oFkq28Cdg"
   },
   "source": [
    "# 3. Baseline defense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "11y75jK98Cdg"
   },
   "outputs": [],
   "source": [
    "def test_defense(defense_method):\n",
    "    models = []\n",
    "    ## Test Pubfig all2all\n",
    "    # print(\"----------------- Testing defense: PubFig all2all -----------------\")\n",
    "    # val_dataset, _, _, _, model = PubFig_all2all()\n",
    "    # try:\n",
    "    #     model = func_timeout(1350, defense_method, args=(model, val_dataset, 1350))\n",
    "    # except FunctionTimedOut:\n",
    "    #     print(\"This test case exceed the maximum executable time!\\n\")\n",
    "    # models.append(model)\n",
    "\n",
    "    ## Test CIFAR-10 SIG\n",
    "    print(\"----------------- Testing defense: CIFAR-10 SIG -----------------\")\n",
    "    val_dataset, _, _, _, model = CIFAR10_SIG()\n",
    "    try:\n",
    "      model = func_timeout(900, defense_method, args=(model, val_dataset,900))\n",
    "    except FunctionTimedOut:\n",
    "        print ( \"This test case exceed the maximum executable time!\\n\")\n",
    "    models.append(model)\n",
    "\n",
    "    ## Test Tiny-Imagenet Narcissus\n",
    "    print(\"----------------- Testing defense: Tiny-Imagenet Narcissus -----------------\")\n",
    "    val_dataset, _, _, _, model = TinyImangeNet_Narcissus()\n",
    "    try:\n",
    "      model = func_timeout(1800, defense_method, args=(model, val_dataset,1800))\n",
    "    except FunctionTimedOut:\n",
    "        print ( \"This test case exceed the maximum executable time!\\n\")\n",
    "    models.append(model)\n",
    "\n",
    "    ## Test GTSRB WaNet & Smooth\n",
    "    print(\"----------------- Testing defense: GTSRB WaNet & Smooth -----------------\")\n",
    "    val_dataset, _, _, _, model = GTSRB_WaNetFrequency()\n",
    "    try:\n",
    "      model = func_timeout(690, defense_method, args=(model, val_dataset,690))\n",
    "    except FunctionTimedOut:\n",
    "        print ( \"This test case exceed the maximum executable time!\\n\")\n",
    "    models.append(model)\n",
    "\n",
    "    # ## Test STL-10\n",
    "    # print(\"----------------- Testing defense: STL-10 -----------------\")\n",
    "    # val_dataset, _, _, _, model = STL10_Clean()\n",
    "    # try:\n",
    "    #   model = func_timeout(450, defense_method, args=(model, val_dataset,450))\n",
    "    # except FunctionTimedOut:\n",
    "    #     print ( \"This test case exceed the maximum executable time!\\n\")\n",
    "    # models.append(model)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2A4BC_518Cdg",
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "#@title I-BAU Defense\n",
    "def IBAU(net, val_dataset, allow_time):\n",
    "    '''Code from https://github.com/YiZeng623/I-BAU'''\n",
    "    allow_time = allow_time * 1000\n",
    "\n",
    "    val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=32, num_workers=4, shuffle=True,\n",
    "                                                 drop_last=True)\n",
    "\n",
    "    images_list, labels_list = [], []\n",
    "    for index, (images, labels) in enumerate(val_dataloader):\n",
    "        images_list.append(images)\n",
    "        labels_list.append(labels)\n",
    "\n",
    "    def loss_inner(perturb, model_params):\n",
    "        images = images_list[0].to(device)\n",
    "        labels = labels_list[0].long().to(device)\n",
    "        per_img = images + perturb[0]\n",
    "        per_logits = net.forward(per_img)\n",
    "        loss = F.cross_entropy(per_logits, labels, reduction='none')\n",
    "        loss_regu = torch.mean(-loss) + 0.001 * torch.pow(torch.norm(perturb[0]), 2)\n",
    "        return loss_regu\n",
    "\n",
    "    def loss_outer(perturb, model_params):\n",
    "        random_pick = np.where(np.random.uniform(0, 1, 32) > 0.97)[0].shape[0]\n",
    "\n",
    "        images, labels = images_list[batchnum].to(device), labels_list[batchnum].long().to(device)\n",
    "        patching = torch.zeros_like(images, device='cuda')\n",
    "        number = images.shape[0]\n",
    "        random_pick = min(number, random_pick)\n",
    "        rand_idx = random.sample(list(np.arange(number)), random_pick)\n",
    "        patching[rand_idx] = perturb[0]\n",
    "        unlearn_imgs = images + patching\n",
    "        logits = net(unlearn_imgs)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        loss = criterion(logits, labels)\n",
    "        return loss\n",
    "\n",
    "    def get_lr(net, loader):\n",
    "        lr_list = [0.1 ** i for i in range(2, 8)]\n",
    "        acc_list = []\n",
    "        for i in range(len(lr_list)):\n",
    "            copy_net = copy.deepcopy(net)\n",
    "            copy_net = copy_net.cuda()\n",
    "            optimizer = torch.optim.Adam(copy_net.parameters(), lr=lr_list[i])\n",
    "            for _, data in enumerate(loader, 0):\n",
    "                length = len(loader)\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.type(torch.LongTensor).to(device)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward + backward\n",
    "                outputs = copy_net(inputs)\n",
    "                loss = F.cross_entropy(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            acc_list.append(get_results(copy_net, loader.dataset))\n",
    "            print(\"lr = \" + str(lr_list[i]) + \" ACC: \" + str(acc_list[-1] * 100))\n",
    "        return 0.1 ** (acc_list.index(max(acc_list)) + 2)\n",
    "\n",
    "    start = torch.cuda.Event(enable_timing=True)\n",
    "    end = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "    #contral the time\n",
    "    every_time = []\n",
    "    for _ in range(5):\n",
    "        every_time.append(0)\n",
    "\n",
    "    start.record()\n",
    "\n",
    "    curr_lr = get_lr(net, val_dataloader)\n",
    "    net = net.cuda()\n",
    "    outer_opt = torch.optim.Adam(net.parameters(), lr=curr_lr)\n",
    "    inner_opt = GradientDescent(loss_inner, 0.1)\n",
    "\n",
    "    end.record()\n",
    "    torch.cuda.synchronize()\n",
    "    every_time.append(start.elapsed_time(end))\n",
    "\n",
    "    net.train()\n",
    "    while (allow_time - np.sum(every_time)) > (np.mean(every_time[-5:]) * 2) and len(every_time) < 155:\n",
    "        start.record()\n",
    "        batch_pert = torch.zeros_like(val_dataset[0][0].unsqueeze(0), requires_grad=True, device='cuda')\n",
    "        batch_lr = 0.0005 * val_dataset[0][0].shape[1] - 0.0155\n",
    "        batch_opt = torch.optim.Adam(params=[batch_pert], lr=batch_lr)\n",
    "\n",
    "        for index, (images, labels) in enumerate(val_dataloader):\n",
    "            images = images.to(device)\n",
    "            ori_lab = torch.argmax(net.forward(images), axis=1).long()\n",
    "            per_logits = net.forward(images + batch_pert)\n",
    "            loss = -F.cross_entropy(per_logits, ori_lab) + 0.001 * torch.pow(torch.norm(batch_pert), 2)\n",
    "            batch_opt.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "            #             if index % 4 == 0:\n",
    "            batch_opt.step()\n",
    "\n",
    "        #unlearn step\n",
    "        for batchnum in range(len(images_list)):\n",
    "            outer_opt.zero_grad()\n",
    "            fixed_point(batch_pert, list(net.parameters()), 5, inner_opt, loss_outer)\n",
    "            #             if batchnum % 4 == 0:\n",
    "            outer_opt.step()\n",
    "\n",
    "        print('Round:', len(every_time) - 5)\n",
    "        end.record()\n",
    "        torch.cuda.synchronize()\n",
    "        every_time.append(start.elapsed_time(end))\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jmy3w60L8Cdh",
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "#@title Neural Cleanse Defense\n",
    "def neural_cleanse(model, val_dataset, allow_time):\n",
    "    '''Code from https://github.com/VinAIResearch/input-aware-backdoor-attack-release'''\n",
    "\n",
    "    class RegressionModel(nn.Module):\n",
    "        def __init__(self, opt, init_mask, init_pattern, model):\n",
    "            self._EPSILON = opt.EPSILON\n",
    "            super(RegressionModel, self).__init__()\n",
    "            self.mask_tanh = nn.Parameter(torch.tensor(init_mask))\n",
    "            self.pattern_tanh = nn.Parameter(torch.tensor(init_pattern))\n",
    "\n",
    "            self.classifier = copy.deepcopy(model)\n",
    "            for param in self.classifier.parameters():\n",
    "                param.requires_grad = False\n",
    "            self.classifier.eval()\n",
    "            self.classifier = self.classifier.cuda()\n",
    "\n",
    "        def forward(self, x):\n",
    "            mask = self.get_raw_mask()\n",
    "            pattern = self.get_raw_pattern()\n",
    "            x = (1 - mask) * x + mask * pattern\n",
    "            return self.classifier(x)\n",
    "\n",
    "        def get_raw_mask(self):\n",
    "            mask = nn.Tanh()(self.mask_tanh)\n",
    "            return mask / (2 + self._EPSILON) + 0.5\n",
    "\n",
    "        def get_raw_pattern(self):\n",
    "            pattern = nn.Tanh()(self.pattern_tanh)\n",
    "            return pattern / (2 + self._EPSILON) + 0.5\n",
    "\n",
    "    class Recorder:\n",
    "        def __init__(self, opt):\n",
    "            super().__init__()\n",
    "\n",
    "            # Best optimization results\n",
    "            self.mask_best = None\n",
    "            self.pattern_best = None\n",
    "            self.reg_best = float(\"inf\")\n",
    "\n",
    "            # Logs and counters for adjusting balance cost\n",
    "            self.logs = []\n",
    "            self.cost_set_counter = 0\n",
    "            self.cost_up_counter = 0\n",
    "            self.cost_down_counter = 0\n",
    "            self.cost_up_flag = False\n",
    "            self.cost_down_flag = False\n",
    "\n",
    "            # Counter for early stop\n",
    "            self.early_stop_counter = 0\n",
    "            self.early_stop_reg_best = self.reg_best\n",
    "\n",
    "            # Cost\n",
    "            self.cost = opt.init_cost\n",
    "            self.cost_multiplier_up = opt.cost_multiplier\n",
    "            self.cost_multiplier_down = opt.cost_multiplier ** 1.5\n",
    "\n",
    "        def reset_state(self, opt):\n",
    "            self.cost = opt.init_cost\n",
    "            self.cost_up_counter = 0\n",
    "            self.cost_down_counter = 0\n",
    "            self.cost_up_flag = False\n",
    "            self.cost_down_flag = False\n",
    "            print(\"Initialize cost to {:f}\".format(self.cost))\n",
    "\n",
    "    def train(opt, init_mask, init_pattern, model, val_dataset):\n",
    "\n",
    "        test_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=128, num_workers=4, shuffle=False,\n",
    "                                                      drop_last=True)\n",
    "\n",
    "        # Build regression model\n",
    "        regression_model = RegressionModel(opt, init_mask, init_pattern, model).cuda()\n",
    "\n",
    "        # Set optimizer\n",
    "        optimizerR = torch.optim.Adam(regression_model.parameters(), lr=opt.lr, betas=(0.5, 0.9))\n",
    "\n",
    "        # Set recorder (for recording best result)\n",
    "        recorder = Recorder(opt)\n",
    "\n",
    "        for epoch in range(opt.epoch):\n",
    "            early_stop = train_step(regression_model, optimizerR, test_dataloader, recorder, epoch, opt)\n",
    "            if early_stop:\n",
    "                break\n",
    "\n",
    "        return recorder, opt\n",
    "\n",
    "    def train_step(regression_model, optimizerR, dataloader, recorder, epoch, opt):\n",
    "        print(\"Epoch {} - Label: {}:\".format(epoch, opt.target_label))\n",
    "        # Set losses\n",
    "        cross_entropy = nn.CrossEntropyLoss()\n",
    "        total_pred = 0\n",
    "        true_pred = 0\n",
    "\n",
    "        # Record loss for all mini-batches\n",
    "        loss_ce_list = []\n",
    "        loss_reg_list = []\n",
    "        loss_list = []\n",
    "        loss_acc_list = []\n",
    "\n",
    "        # Set inner early stop flag\n",
    "        inner_early_stop_flag = False\n",
    "        for batch_idx, (inputs, labels) in enumerate(dataloader):\n",
    "            # Forwarding and update model\n",
    "            optimizerR.zero_grad()\n",
    "\n",
    "            inputs = inputs.cuda()\n",
    "            sample_num = inputs.shape[0]\n",
    "            total_pred += sample_num\n",
    "            target_labels = torch.ones((sample_num), dtype=torch.int64).cuda() * opt.target_label\n",
    "            predictions = regression_model(inputs)\n",
    "\n",
    "            loss_ce = cross_entropy(predictions, target_labels)\n",
    "            loss_reg = torch.norm(regression_model.get_raw_mask(), 2)\n",
    "            total_loss = loss_ce + recorder.cost * loss_reg\n",
    "            total_loss.backward()\n",
    "            optimizerR.step()\n",
    "\n",
    "            # Record minibatch information to list\n",
    "            minibatch_accuracy = torch.sum(\n",
    "                torch.argmax(predictions, dim=1) == target_labels).detach() * 100.0 / sample_num\n",
    "            loss_ce_list.append(loss_ce.detach())\n",
    "            loss_reg_list.append(loss_reg.detach())\n",
    "            loss_list.append(total_loss.detach())\n",
    "            loss_acc_list.append(minibatch_accuracy)\n",
    "\n",
    "            true_pred += torch.sum(torch.argmax(predictions, dim=1) == target_labels).detach()\n",
    "\n",
    "        loss_ce_list = torch.stack(loss_ce_list)\n",
    "        loss_reg_list = torch.stack(loss_reg_list)\n",
    "        loss_list = torch.stack(loss_list)\n",
    "        loss_acc_list = torch.stack(loss_acc_list)\n",
    "\n",
    "        avg_loss_ce = torch.mean(loss_ce_list)\n",
    "        avg_loss_reg = torch.mean(loss_reg_list)\n",
    "        avg_loss_acc = torch.mean(loss_acc_list)\n",
    "\n",
    "        # Check to save best mask or not\n",
    "        if avg_loss_acc >= opt.atk_succ_threshold and avg_loss_reg < recorder.reg_best:\n",
    "            recorder.mask_best = regression_model.get_raw_mask().detach()\n",
    "            recorder.pattern_best = regression_model.get_raw_pattern().detach()\n",
    "            recorder.reg_best = avg_loss_reg\n",
    "            print(\" Updated !!!\")\n",
    "\n",
    "        # Show information\n",
    "        print(\n",
    "            \"  Result: Accuracy: {:.3f} | Cross Entropy Loss: {:.6f} | Reg Loss: {:.6f} | Reg best: {:.6f}\".format(\n",
    "                true_pred * 100.0 / total_pred, avg_loss_ce, avg_loss_reg, recorder.reg_best\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Check early stop\n",
    "        if opt.early_stop:\n",
    "            if recorder.reg_best < float(\"inf\"):\n",
    "                if recorder.reg_best >= opt.early_stop_threshold * recorder.early_stop_reg_best:\n",
    "                    recorder.early_stop_counter += 1\n",
    "                else:\n",
    "                    recorder.early_stop_counter = 0\n",
    "\n",
    "            recorder.early_stop_reg_best = min(recorder.early_stop_reg_best, recorder.reg_best)\n",
    "\n",
    "            if (\n",
    "                    recorder.cost_down_flag\n",
    "                    and recorder.cost_up_flag\n",
    "                    and recorder.early_stop_counter >= opt.early_stop_patience\n",
    "            ):\n",
    "                print(\"Early_stop !!!\")\n",
    "                inner_early_stop_flag = True\n",
    "\n",
    "        if not inner_early_stop_flag:\n",
    "            # Check cost modification\n",
    "            if recorder.cost == 0 and avg_loss_acc >= opt.atk_succ_threshold:\n",
    "                recorder.cost_set_counter += 1\n",
    "                if recorder.cost_set_counter >= opt.patience:\n",
    "                    recorder.reset_state(opt)\n",
    "            else:\n",
    "                recorder.cost_set_counter = 0\n",
    "\n",
    "            if avg_loss_acc >= opt.atk_succ_threshold:\n",
    "                recorder.cost_up_counter += 1\n",
    "                recorder.cost_down_counter = 0\n",
    "            else:\n",
    "                recorder.cost_up_counter = 0\n",
    "                recorder.cost_down_counter += 1\n",
    "\n",
    "            if recorder.cost_up_counter >= opt.patience:\n",
    "                recorder.cost_up_counter = 0\n",
    "                print(\"Up cost from {} to {}\".format(recorder.cost, recorder.cost * recorder.cost_multiplier_up))\n",
    "                recorder.cost *= recorder.cost_multiplier_up\n",
    "                recorder.cost_up_flag = True\n",
    "\n",
    "            elif recorder.cost_down_counter >= opt.patience:\n",
    "                recorder.cost_down_counter = 0\n",
    "                print(\"Down cost from {} to {}\".format(recorder.cost, recorder.cost / recorder.cost_multiplier_down))\n",
    "                recorder.cost /= recorder.cost_multiplier_down\n",
    "                recorder.cost_down_flag = True\n",
    "\n",
    "            # Save the final version\n",
    "            if recorder.mask_best is None:\n",
    "                recorder.mask_best = regression_model.get_raw_mask().detach()\n",
    "                recorder.pattern_best = regression_model.get_raw_pattern().detach()\n",
    "\n",
    "        return inner_early_stop_flag\n",
    "\n",
    "    class opt:\n",
    "        total_label = np.unique(val_dataset.targets).shape[0]\n",
    "        input_height, input_width, input_channel = val_dataset[0][0].shape[1], val_dataset[0][0].shape[2], \\\n",
    "        val_dataset[0][0].shape[0]\n",
    "        EPSILON = 1e-7\n",
    "        lr = 1e-1\n",
    "        init_cost = 1e-3\n",
    "        cost_multiplier = 2.0\n",
    "        epoch = 1\n",
    "        atk_succ_threshold = 99.0\n",
    "        early_stop_threshold = 99.0\n",
    "        early_stop = True\n",
    "        patience = 5\n",
    "\n",
    "    opt = opt()\n",
    "\n",
    "    init_mask = np.ones((1, opt.input_height, opt.input_width)).astype(np.float32)\n",
    "    init_pattern = np.ones((opt.input_channel, opt.input_height, opt.input_width)).astype(np.float32)\n",
    "\n",
    "    masks = []\n",
    "    patterns = []\n",
    "    idx_mapping = {}\n",
    "\n",
    "    for target_label in range(opt.total_label):\n",
    "        print(\"----------------- Analyzing label: {} -----------------\".format(target_label))\n",
    "        opt.target_label = target_label\n",
    "        recorder, opt = train(opt, init_mask, init_pattern, model, val_dataset)\n",
    "\n",
    "        mask = recorder.mask_best\n",
    "        masks.append(mask)\n",
    "        pattern = recorder.pattern_best\n",
    "        patterns.append(pattern)\n",
    "\n",
    "        idx_mapping[target_label] = len(masks) - 1\n",
    "\n",
    "    l1_norm_list = torch.stack([torch.sum(torch.abs(m)) for m in masks])\n",
    "    print(\"{} labels found\".format(len(l1_norm_list)))\n",
    "    print(\"Norm values: {}\".format(l1_norm_list))\n",
    "\n",
    "    def outlier_detection(l1_norm_list, idx_mapping, opt):\n",
    "        print(\"-\" * 30)\n",
    "        print(\"Determining whether model is backdoor\")\n",
    "        consistency_constant = 1.4826\n",
    "        median = torch.median(l1_norm_list)\n",
    "        mad = consistency_constant * torch.median(torch.abs(l1_norm_list - median))\n",
    "        min_mad = torch.abs(torch.min(l1_norm_list) - median) / mad\n",
    "\n",
    "        print(\"Median: {}, MAD: {}\".format(median, mad))\n",
    "        print(\"Anomaly index: {}\".format(min_mad))\n",
    "\n",
    "        if min_mad < 2:\n",
    "            print(\"Not a backdoor model\")\n",
    "        else:\n",
    "            print(\"This is a backdoor model\")\n",
    "\n",
    "        flag_list = []\n",
    "        for y_label in idx_mapping:\n",
    "            if l1_norm_list[idx_mapping[y_label]] > median:\n",
    "                continue\n",
    "            if torch.abs(l1_norm_list[idx_mapping[y_label]] - median) / mad > 2:\n",
    "                flag_list.append((y_label, l1_norm_list[idx_mapping[y_label]]))\n",
    "\n",
    "        if len(flag_list) > 0:\n",
    "            flag_list = sorted(flag_list, key=lambda x: x[1])\n",
    "\n",
    "        print(\n",
    "            \"Flagged label list: {}\".format(\n",
    "                \",\".join([\"{}: {}\".format(y_label, l_norm) for y_label, l_norm in flag_list]))\n",
    "        )\n",
    "\n",
    "        return [y_label for y_label, _ in flag_list]\n",
    "\n",
    "    poi_label_list = outlier_detection(l1_norm_list, idx_mapping, opt)\n",
    "\n",
    "    if len(poi_label_list) == 0:\n",
    "        return model\n",
    "\n",
    "    class unlearning_ds(Dataset):\n",
    "        def __init__(self, dataset, mask, trigger, patch_ratio):\n",
    "            self.dataset = dataset\n",
    "            self.patch_list = random.sample(list(np.arange(len(dataset))), int(len(dataset) * patch_ratio))\n",
    "            self.mask = mask\n",
    "            self.trigger = trigger\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            image = self.dataset[idx][0]\n",
    "            label = self.dataset[idx][1]\n",
    "            if idx in self.patch_list:\n",
    "                image = (image + self.mask * (self.trigger - image))\n",
    "            image = torch.clamp(image, -1, 1)\n",
    "            return (image, label)\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.dataset)\n",
    "\n",
    "    for i in poi_label_list:\n",
    "        curr_masks = masks[i].cpu()\n",
    "        curr_pattern = patterns[i].cpu()\n",
    "        ul_set = unlearning_ds(val_dataset, curr_masks, curr_pattern, 0.2)\n",
    "        ul_loader = torch.utils.data.DataLoader(ul_set, batch_size=128, num_workers=4, shuffle=True, drop_last=True)\n",
    "\n",
    "        model.train()\n",
    "        outer_opt = torch.optim.SGD(params=model.parameters(), lr=8e-2)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        for _ in range(10):\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            acc_rec = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(ul_loader):\n",
    "                inputs, targets = inputs.cuda(), targets.type(torch.LongTensor).cuda()\n",
    "                outer_opt.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                loss.backward()\n",
    "                outer_opt.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "            print('Unlearn Acc: %.3f%% (%d/%d)'\n",
    "                  % (100. * correct / total, correct, total))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GFxsTR3E8Cdj"
   },
   "source": [
    "# 4. Implement your defense method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8KQKqgGs8Cdj"
   },
   "outputs": [],
   "source": [
    "from torch.cuda.amp import autocast as autocast, GradScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms.v2 as transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "torch.manual_seed(17)\n",
    "\n",
    "# Augment space\n",
    "num_bins = 31\n",
    "augmentation_space = {\n",
    "    # op_name: (magnitudes, signed)\n",
    "    \"Identity\": (torch.tensor(0.0), False),\n",
    "    \"ShearX\": (torch.linspace(0.0, 0.99, num_bins), True),\n",
    "    \"ShearY\": (torch.linspace(0.0, 0.99, num_bins), True),\n",
    "    \"TranslateX\": (torch.linspace(0.0, 32.0, num_bins), True),\n",
    "    \"TranslateY\": (torch.linspace(0.0, 32.0, num_bins), True),\n",
    "    \"Rotate\": (torch.linspace(0.0, 135.0, num_bins), True),\n",
    "    \"Brightness\": (torch.linspace(0.0, 0.99, num_bins), True),\n",
    "    \"Color\": (torch.linspace(0.0, 0.99, num_bins), True),\n",
    "    \"Contrast\": (torch.linspace(0.0, 0.99, num_bins), True),\n",
    "    \"Sharpness\": (torch.linspace(0.0, 0.99, num_bins), True),\n",
    "    \"Posterize\": (8 - (torch.arange(num_bins) / ((num_bins - 1) / 6)).round().int(), False),\n",
    "    \"Solarize\": (torch.linspace(255.0, 0.0, num_bins), False),\n",
    "    \"AutoContrast\": (torch.tensor(0.0), False),\n",
    "    \"Equalize\": (torch.tensor(0.0), False),\n",
    "}\n",
    "\n",
    "def clean_model(model, dataset, allow_time):\n",
    "    # Data augmentation\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(0.5),\n",
    "        transforms.TrivialAugmentWide(),\n",
    "        transforms.RandomErasing(p=1, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=255, inplace=False),\n",
    "        transforms.GaussianBlur(5, 20),\n",
    "    ])\n",
    "\n",
    "    # Cutmix 随机产生一个box区域的四个坐标\n",
    "    def rand_bbox(size, lam):\n",
    "        W = size[2]\n",
    "        H = size[3]\n",
    "        cut_rat = np.sqrt(1. - lam)\n",
    "        cut_w = np.int16(W * cut_rat)\n",
    "        cut_h = np.int16(H * cut_rat)\n",
    "\n",
    "        # uniform\n",
    "        cx = np.random.randint(W)\n",
    "        cy = np.random.randint(H)\n",
    "\n",
    "        bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "        bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "        bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "        bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "        return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "    # TorchEvaluator example\n",
    "    import torch\n",
    "    import torch.nn.functional as F\n",
    "\n",
    "    # The user customized `training_step` should follow this paramter signature,\n",
    "    # the first is `batch`, the second is `model`,\n",
    "    # and the return value of `training_step` should be loss, or tuple with the first element is loss,\n",
    "    # or dict with key 'loss'.\n",
    "    def training_step(batch, model, transforms, *args, **kwargs):\n",
    "        images, labels = batch\n",
    "        images, labels = images.to(device, non_blocking=True), labels.type(torch.LongTensor).to(device,non_blocking=True)\n",
    "        loss_fn = 0\n",
    "        with autocast():\n",
    "            if transforms:\n",
    "                images = train_transform(images)\n",
    "            r = np.random.rand(1)\n",
    "            beta = dataset[0][0].shape[0] / 2\n",
    "            cutmix_prob = 0.25\n",
    "            if beta > 0 and r < cutmix_prob:\n",
    "                # generate mixed sample\n",
    "                lam = np.random.beta(beta, beta)  #随机的lam\n",
    "                rand_index = torch.randperm(images.size()[0]).cuda()  #在batch中随机抽取一个样本，记为i\n",
    "                target_a = labels\n",
    "                target_b = labels[rand_index]  #获取该样本的标签\n",
    "                bbx1, bby1, bbx2, bby2 = rand_bbox(images.size(), lam)  #随机产生一个box的四个坐标\n",
    "                images[:, :, bbx1:bbx2, bby1:bby2] = images[rand_index, :, bbx1:bbx2,\n",
    "                                                     bby1:bby2]  #将样本i中box的像素值填充该批数据中相同区域\n",
    "                # adjust lambda to exactly match pixel ratio\n",
    "                lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (images.size()[-1] * images.size()[-2]))  #按照box面积计算lam\n",
    "                # compute output\n",
    "                per_logits = model(images + batch_pert)\n",
    "                loss_fn = -F.cross_entropy(per_logits, target_a) * lam + -F.cross_entropy(per_logits, target_b) * (\n",
    "                        1. - lam) + 0.001 * torch.pow(torch.norm(batch_pert), 2)  #通过lam融合损失\n",
    "            else:\n",
    "                # compute output\n",
    "                ori_lab = torch.argmax(model(images), axis=1).long()\n",
    "                per_logits = model(images + batch_pert)\n",
    "                loss_fn = -F.cross_entropy(per_logits, ori_lab) + 0.001 * torch.pow(torch.norm(batch_pert), 2)\n",
    "\n",
    "            if torch.any(torch.isnan(loss_fn)) or torch.any(torch.isinf(loss_fn)):\n",
    "                raise ValueError(\"Inf or nan loss value: use fp32 training instead!\")\n",
    "\n",
    "        return loss_fn\n",
    "\n",
    "    # The user customized `training_model` should follow this paramter signature,\n",
    "    # (model, optimizer, `training_step`, lr_scheduler, max_steps, max_epochs, ...),\n",
    "    # and note that `training_step`` should be defined out of `training_model`.\n",
    "    def training_model(model, optimizer, lr_scheduler, max_steps, max_epochs, *args, **kwargs):\n",
    "        # max_steps, max_epochs might be None, which means unlimited training time,\n",
    "        # so here we need set a default termination condition (by default, total_epochs=10, total_steps=100000).\n",
    "        total_epochs = max_epochs if max_epochs else 1000\n",
    "        total_steps = max_steps if max_steps else 10000000\n",
    "        current_step = 0\n",
    "\n",
    "        # init dataloader\n",
    "        batch_size = 32\n",
    "        train_dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, num_workers=4, shuffle=True,\n",
    "                                                 pin_memory=True)\n",
    "\n",
    "        images_list, labels_list = [], []\n",
    "        for index, (images, labels) in enumerate(train_dataloader):\n",
    "            images_list.append(images)\n",
    "            labels_list.append(labels)\n",
    "\n",
    "        def loss_inner(perturb, model_params):\n",
    "            images = images_list[0].to(device)\n",
    "            labels = labels_list[0].long().to(device)\n",
    "            per_img = images + perturb[0]\n",
    "            per_logits = model.forward(per_img)\n",
    "            loss = F.cross_entropy(per_logits, labels, reduction='none')\n",
    "            loss_regu = torch.mean(-loss) + 0.001 * torch.pow(torch.norm(perturb[0]), 2)\n",
    "            return loss_regu\n",
    "\n",
    "        def loss_outer(perturb, model_params):\n",
    "            random_pick = np.where(np.random.uniform(0, 1, 32) > 0.97)[0].shape[0]\n",
    "\n",
    "            images, labels = images_list[batchnum].to(device), labels_list[batchnum].long().to(device)\n",
    "            patching = torch.zeros_like(images, device='cuda')\n",
    "            number = images.shape[0]\n",
    "            random_pick = min(number, random_pick)\n",
    "            rand_idx = random.sample(list(np.arange(number)), random_pick)\n",
    "            patching[rand_idx] = perturb[0]\n",
    "            unlearn_imgs = images + patching\n",
    "            logits = model(unlearn_imgs)\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            loss = criterion(logits, labels)\n",
    "            return loss\n",
    "\n",
    "        def get_lr(model, loader):\n",
    "            lr_list = [0.1 ** i for i in range(2, 8)]\n",
    "            acc_list = []\n",
    "            for i in range(len(lr_list)):\n",
    "                copy_net = copy.deepcopy(model)\n",
    "                copy_net = copy_net.cuda()\n",
    "                optimizer = torch.optim.AdamW(copy_net.parameters(), lr=lr_list[i])\n",
    "\n",
    "                scaler = GradScaler()\n",
    "\n",
    "                for _, data in enumerate(loader, 0):\n",
    "                    length = len(loader)\n",
    "                    inputs, labels = data\n",
    "                    inputs, labels = inputs.to(device), labels.type(torch.LongTensor).to(device)\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward + backward\n",
    "                    # outputs = copy_net(inputs)\n",
    "                    # loss = F.cross_entropy(outputs, labels)\n",
    "                    # loss.backward()\n",
    "                    # optimizer.step()\n",
    "\n",
    "                    # forward + backward + optimize\n",
    "                    with autocast():\n",
    "                        outputs = copy_net(inputs)\n",
    "                        loss_lr = F.cross_entropy(outputs, labels)\n",
    "                        if torch.any(torch.isnan(loss_lr)) or torch.any(torch.isinf(loss_lr)):\n",
    "                            raise ValueError(\"Inf or nan loss value: use fp32 training instead!\")\n",
    "                    #                     seems that retain_graph cannot set up with autocast\n",
    "                    scaler.scale(loss_lr).backward()\n",
    "                    #             if index % 4 == 0:\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                acc_list.append(get_results(copy_net, loader.dataset))\n",
    "                print(\"lr = \" + str(lr_list[i]) + \" ACC: \" + str(acc_list[-1] * 100))\n",
    "            return 0.1 ** (acc_list.index(max(acc_list)) + 2)\n",
    "\n",
    "        start = torch.cuda.Event(enable_timing=True)\n",
    "        end = torch.cuda.Event(enable_timing=True)\n",
    "        #contral the time\n",
    "        every_time = []\n",
    "        for _ in range(5):\n",
    "            every_time.append(0)\n",
    "\n",
    "        start.record()\n",
    "\n",
    "        curr_lr = get_lr(model, train_dataloader)\n",
    "        model = model.cuda()\n",
    "        outer_opt = torch.optim.AdamW(model.parameters(), lr=curr_lr)\n",
    "        inner_opt = GradientDescent(loss_inner, 0.1)\n",
    "\n",
    "        end.record()\n",
    "        torch.cuda.synchronize()\n",
    "        every_time.append(start.elapsed_time(end))\n",
    "\n",
    "        lr = []\n",
    "        max_round = 250\n",
    "        swa_start = 250\n",
    "        curr_round = -1\n",
    "        batch_lr = 0.005\n",
    "\n",
    "        # swa_model = AveragedModel(model)\n",
    "        batch_pert = torch.zeros_like(dataset[0][0].unsqueeze(0), requires_grad=True, device='cuda')\n",
    "        batch_opt = optimizer\n",
    "        scheduler = lr_scheduler\n",
    "        # swa_scheduler = SWALR(batch_opt, swa_lr=0.0005)\n",
    "\n",
    "\n",
    "        scaler = GradScaler()\n",
    "        model.train()\n",
    "\n",
    "        for epoch in range(total_epochs):\n",
    "            if (allow_time - np.sum(every_time)) > (np.mean(every_time[-5:]) * 2):\n",
    "                start.record()\n",
    "                for batch in train_dataloader:\n",
    "\n",
    "                    batch_opt.zero_grad()\n",
    "                    loss_fn = training_step(batch, model, True)\n",
    "                    scaler.scale(loss_fn).backward(retain_graph=True)\n",
    "                    scaler.step(batch_opt)\n",
    "                    scaler.update()\n",
    "\n",
    "                    #unlearn step\n",
    "                    for batchnum in range(len(images_list)):\n",
    "                        outer_opt.zero_grad()\n",
    "                        if curr_round % 5 == 0:\n",
    "                            fixed_point(batch_pert, list(model.parameters()), 5, inner_opt, loss_outer)\n",
    "                        # if batchnum % 4 == 0:\n",
    "                        outer_opt.step()\n",
    "\n",
    "                    scheduler.step()\n",
    "                    lr.append(scheduler.get_last_lr())\n",
    "\n",
    "                    # if curr_round > swa_start:\n",
    "                    #     swa_model.update_parameters(model)\n",
    "                    #     swa_scheduler.step()\n",
    "                    # else:\n",
    "                    #     scheduler.step()\n",
    "                    #     lr.append(scheduler.get_last_lr())\n",
    "\n",
    "                    print('Round:', len(every_time) - 5)\n",
    "                    end.record()\n",
    "                    torch.cuda.synchronize()\n",
    "                    every_time.append(start.elapsed_time(end))\n",
    "                plt.plot(np.arange(len(lr)), lr)\n",
    "                plt.show()\n",
    "            else: break\n",
    "\n",
    "    import nni\n",
    "    max_epochs = 200\n",
    "    max_steps = max_epochs * len(dataset)\n",
    "\n",
    "    batch_pert = torch.zeros_like(dataset[0][0].unsqueeze(0), requires_grad=True, device='cuda')\n",
    "    batch_lr = 0.0005*dataset[0][0].shape[1]-0.0155\n",
    "    traced_optimizer = nni.trace(torch.optim.AdamW)([batch_pert], lr=batch_lr)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(traced_optimizer, max_lr=0.005)\n",
    "\n",
    "    from nni.contrib.compression import TorchEvaluator\n",
    "    evaluator = TorchEvaluator(training_func=training_model, optimziers=traced_optimizer, lr_scheduler=lr_scheduler, training_step=training_step)\n",
    "\n",
    "    from nni.contrib.compression.pruning import MovementPruner\n",
    "    from nni.compression.pytorch.speedup.v2 import ModelSpeedup\n",
    "    config_list = [{\n",
    "        'op_types': ['Conv2d', 'Linear'],\n",
    "        'op_names_re': ['bert\\.encoder\\.layer\\.[0-9]*\\.attention\\.*'],\n",
    "        'sparse_threshold': 0.2,\n",
    "        'max_sparse_ratio': 0.8,\n",
    "        'granularity': 'default',\n",
    "        'target_settings': {\n",
    "            'weight': {\n",
    "                'align': {\n",
    "                    'module_name': 'conv',\n",
    "                    'target_name': 'weight',\n",
    "                    'dims': [0],\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }]\n",
    "    pruner = MovementPruner(model, config_list, evaluator, warmup_step=9000, cooldown_begin_step=36000, regular_scale=10)\n",
    "    pruner.compress(None, 4)\n",
    "    pruner.unwrap_model()\n",
    "    masks = pruner.get_masks()\n",
    "    num_classes = model.fc.out_features\n",
    "    num_channels = model.conv1.in_channels\n",
    "    # 求模型输入的长宽\n",
    "    input_size = model.conv1.weight.size(2)\n",
    "    dummy_input = torch.randn(num_classes, num_channels, input_size, input_size, device=\"cuda\")\n",
    "    ModelSpeedup(model, dummy_input, masks, 'cuda')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5. Test defense"
   ],
   "metadata": {
    "id": "THKu7ewXHYGi"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w6fo4MlW8Cdj"
   },
   "outputs": [],
   "source": [
    "# Get the defended model\n",
    "models = test_defense(clean_model)\n",
    "\n",
    "# Test all attack\n",
    "## Test Pubfig all2all\n",
    "# print(\"----------------- Testing defense result: PubFig all2all -----------------\")\n",
    "# _, test_dataset, asr_dataset, pacc_dataset, _ = PubFig_all2all()\n",
    "# model = models\n",
    "# print('ACC：%.3f%%' % (100 * get_results(model, test_dataset)))\n",
    "# print('ASR %.3f%%' % (100 * get_results(model, asr_dataset)))\n",
    "# print('PACC %.3f%%' % (100 * get_results(model, pacc_dataset)))\n",
    "\n",
    "# ## Test CIFAR-10 SIG\n",
    "print(\"----------------- Testing defense result: CIFAR-10 SIG -----------------\")\n",
    "_, test_dataset, asr_dataset, pacc_dataset, _ = CIFAR10_SIG()\n",
    "model = models[0]\n",
    "print('ACC：%.3f%%' % (100 * get_results(model, test_dataset)))\n",
    "print('ASR %.3f%%' % (100 * get_results(model, asr_dataset)))\n",
    "print('PACC %.3f%%' % (100 * get_results(model, pacc_dataset)))\n",
    "#\n",
    "# ## Test Tiny-Imagenet Narcissus\n",
    "print(\"----------------- Testing defense result: Tiny-Imagenet Narcissus -----------------\")\n",
    "_, test_dataset, asr_dataset, pacc_dataset, _ = TinyImangeNet_Narcissus()\n",
    "model = models[1]\n",
    "print('ACC：%.3f%%' % (100 * get_results(model, test_dataset)))\n",
    "print('ASR %.3f%%' % (100 * get_results(model, asr_dataset)))\n",
    "print('PACC %.3f%%' % (100 * get_results(model, pacc_dataset)))\n",
    "#\n",
    "# ## Test GTSRB WaNet & Smooth\n",
    "print(\"----------------- Testing defense result: GTSRB WaNet & Smooth -----------------\")\n",
    "_, test_dataset, asr_dataset, pacc_dataset, _ = GTSRB_WaNetFrequency()\n",
    "model = models[2]\n",
    "print('ACC：%.3f%%' % (100 * get_results(model, test_dataset)))\n",
    "print('WaNet ASR %.3f%%' % (100 * get_results(model, asr_dataset[0])))\n",
    "print('WaNet PACC %.3f%%' % (100 * get_results(model, pacc_dataset[0])))\n",
    "print('Smooth ASR %.3f%%' % (100 * get_results(model, asr_dataset[1])))\n",
    "print('Smooth PACC %.3f%%' % (100 * get_results(model, pacc_dataset[1])))\n",
    "#\n",
    "# ## Test STL-10\n",
    "# print(\"----------------- Testing defense result: STL-10 -----------------\")\n",
    "# _, test_dataset, _, _, _ = STL10_Clean()\n",
    "# model = models[3]\n",
    "# print('ACC：%.3f%%' % (100 * get_results(model, test_dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 6. For colab user to release GPU memory"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! apt-get install psmisc\n",
    "! /opt/bin/nvidia-smi\n",
    "! sudo fuser -v/dev/nvidia *"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! kill -9[PID]"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b8be34f2a64f133f414bd034f75b72cc1c8d29070f6944ffe8bd65ff6cd5b9f"
   }
  },
  "colab": {
   "provenance": [],
   "collapsed_sections": [
    "WkI4fII__74u",
    "TV_oFkq28Cdg",
    "GFxsTR3E8Cdj",
    "THKu7ewXHYGi"
   ]
  },
  "gpuClass": "standard"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
